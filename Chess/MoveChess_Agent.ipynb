{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL_Chess_Week_10_IterEva.ipynb","provenance":[{"file_id":"1_XQuxOnRbvsPscCQmAnaYW80t-fBOT2K","timestamp":1611721813112},{"file_id":"12u_mvyDU9TRq_NIs3j9esUoPOmZvrWH3","timestamp":1610780795696}],"collapsed_sections":[],"authorship_tag":"ABX9TyOpKL5Q4vO2VSRY4kL/rGBA"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Uq9ziHnmKvkI"},"source":["There are two major intermidiate steps when solving chess problem:\n","1. Move Chess:\n","\n",">> Objective: find the shortest path between 2 spots on a chess board\n","\n",">> Motivation: Move Chess effectively\n","\n","2. Capture Chess\n","\n",">> Objective: capture as many pieces from the opponent within centain fullmoves\n","\n",">> Motivation: Piece captures as one way of reward.\n","\n","\n","Today we focus on Move chess"]},{"cell_type":"markdown","metadata":{"id":"aTDi57bymfrV"},"source":["# Load and Import Package"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VS1maVXrqT3D","executionInfo":{"status":"ok","timestamp":1612312368524,"user_tz":300,"elapsed":9378,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"1622589f-ff22-44e2-9853-860f53dcd024"},"source":["!pip install --upgrade git+https://github.com/arjangroen/RLC.git \n","!pip install python-chess  \n","# Python-Chess is the Python Chess Package that handles the chess environment"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/arjangroen/RLC.git\n","  Cloning https://github.com/arjangroen/RLC.git to /tmp/pip-req-build-1j_j4u2a\n","  Running command git clone -q https://github.com/arjangroen/RLC.git /tmp/pip-req-build-1j_j4u2a\n","Building wheels for collected packages: RLC\n","  Building wheel for RLC (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for RLC: filename=RLC-0.3-cp36-none-any.whl size=22566 sha256=9755a8ef390e3860f83cb104b731447b9b2049feaf8489bf140fc411a9887786\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-o4kpj34b/wheels/04/68/a5/cb835cd3d76a49de696a942739c71a56bfe66d0d8ea7b4b446\n","Successfully built RLC\n","Installing collected packages: RLC\n","Successfully installed RLC-0.3\n","Requirement already satisfied: python-chess in /usr/local/lib/python3.6/dist-packages (0.23.11)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UiRPTTKQBu6R"},"source":["from RLC.move_chess.environment import Board\n","from RLC.move_chess.agent import Piece\n","from RLC.move_chess.learn import Reinforce\n","import inspect\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ct6eei62C0dL","executionInfo":{"status":"ok","timestamp":1612312368526,"user_tz":300,"elapsed":6487,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"7c44d2a0-f473-4c7f-c00b-a0fc835f3fa2"},"source":["env = Board()\n","env.render()\n","env.visual_board "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['[S]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[ ]'],\n"," ['[ ]', '[ ]', '[ ]', '[ ]', '[ ]', '[F]', '[ ]', '[ ]']]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"JqVqulX-WJQT"},"source":["# King (One Step)\n"]},{"cell_type":"code","metadata":{"id":"dhYEnLH7bhU0"},"source":["# Radom Walk\n","eva1 = []\n","for i in range(50):\n","  #r.policy_iteration()\n","  p = Piece(piece='king') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva1.append(len(actions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaGBeQfAZ-WT"},"source":["# Policy Iteration\n","eva2 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='king') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration()\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva2.append(len(actions))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoaHIPLaRYi7"},"source":["eva3 = [] # a empty list to store number of step to get to desired position\n","for i in range(50): # repeat 50 times\n","  p = Piece(piece='king') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) # place king on the board at (0,0) by default\n","  r.policy_iteration(k=1) # when k=1, it's value iteration\n","  states, actions, rewards = r.play_episode(state = (0,0),\n","                 max_steps=1e3, \n","                 epsilon=0.1) # move chess until it gets to (5,7) by default\n","\n","  eva3.append(len(actions)) # add number of steps to the list\n","eva3 # print list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"njYUpaXZ2YQc"},"source":["number of step required for the agent to go from (0,0) to (5,7)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jdL3GpWbj8l","executionInfo":{"status":"ok","timestamp":1612312809166,"user_tz":300,"elapsed":51990,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"93ead17a-782b-4381-ec52-04553c6639ff"},"source":["print(\"None:\", \"Mean:\", np.mean(eva1), \"Var:\", np.var(eva1))\n","print(\"PI:\", \"Mean:\", np.mean(eva2), \"Var:\", np.var(eva2))\n","print(\"VI:\", \"Mean:\", np.mean(eva3), \"Var:\", np.var(eva3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None: Mean: 213.2 Var: 24388.479999999996\n","PI: Mean: 8.96 Var: 1.5183999999999997\n","VI: Mean: 9.1 Var: 2.65\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDRSwYPTh7U4","executionInfo":{"status":"ok","timestamp":1612316194316,"user_tz":300,"elapsed":259,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"bd243b0e-e664-4d83-a67f-fc45c1dc5864"},"source":["stats.ttest_rel(eva2, eva3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ttest_relResult(statistic=0.5734623443633284, pvalue=0.5689544686260503)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"CqdF7m5U-MN2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612323546734,"user_tz":300,"elapsed":290,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"4d3b9aa6-61d8-4c07-a11f-03a7b39697d4"},"source":["print(eva3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[11, 8, 9, 10, 8, 8, 8, 8, 9, 8, 8, 8, 8, 10, 12, 10, 9, 8, 8, 8, 8, 10, 11, 8, 8, 8, 11, 8, 12, 8, 12, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 10, 9, 8, 12, 9]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gDLd05H9d4Wo"},"source":["# Knight (L shape) "]},{"cell_type":"code","metadata":{"id":"4kuKwVRVHb7N"},"source":["# Radom Walk\n","eva1 = []\n","for i in range(50):\n","  #r.policy_iteration()\n","  p = Piece(piece='knight') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva1.append(len(actions))\n","\n","# Policy Iteration\n","eva2 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='knight') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration()\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva2.append(len(actions))\n","\n","eva3 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='knight') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration(k=1)\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva3.append(len(actions))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3Ac_eiYgEBY","executionInfo":{"status":"ok","timestamp":1612320858287,"user_tz":300,"elapsed":292,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"9fba1131-28e3-4c68-9696-db55db0003b1"},"source":["print(\"None:\", \"Mean:\", np.mean(eva1), \"Var:\", np.var(eva1))\n","print(\"PI:\", \"Mean:\", np.mean(eva2), \"Var:\", np.var(eva2))\n","print(\"VI:\", \"Mean:\", np.mean(eva3), \"Var:\", np.var(eva3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None: Mean: 169.38 Var: 22948.0356\n","PI: Mean: 5.58 Var: 1.0836\n","VI: Mean: 5.42 Var: 0.7636\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_4z5dlkiTzW","executionInfo":{"status":"ok","timestamp":1612316308207,"user_tz":300,"elapsed":277,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"bed81792-2da3-4f2c-c342-5203ba53bc1b"},"source":["stats.ttest_rel(eva2, eva3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ttest_relResult(statistic=0.766619949470751, pvalue=0.4469853625430449)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"uYnnPyFCiQ8h"},"source":["There are three functions in the framework^{[2]}:\n","\n","1. State Evaluation: if we want our agent to optimize its rewards, we want its policy to guide behavior towards the states with the highest value. Since there can be multiple actions (a) and multiple successor states they are summed and weighted by their probability (pi). Successor state values are discounted with discount factor (gamma) that varies between 0 and 1.\n","\n","2. Policy Evaluation: apply state evaluation for each state.\n","\n","3. Policy Improvement: the act of making the policy greedy with respect to the value function."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9QT3jFAxhZXs"},"source":["# Bishop (Diagnally) "]},{"cell_type":"code","metadata":{"id":"_-zxfgIsF1Ai"},"source":["# Radom Walk\n","eva1 = []\n","for i in range(50):\n","  #r.policy_iteration()\n","  p = Piece(piece='bishop') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva1.append(len(actions))\n","\n","# Policy Iteration\n","eva2 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='bishop') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration()\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva2.append(len(actions))\n","\n","eva3 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='bishop') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration(k=1)\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva3.append(len(actions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dm-fTjB2F8ym","executionInfo":{"status":"ok","timestamp":1612313115091,"user_tz":300,"elapsed":112459,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"dc9ae60c-0fcc-49e7-8fc7-5f6c3cff6a84"},"source":["print(\"None:\", \"Mean:\", np.mean(eva1), \"Var:\", np.var(eva1))\n","print(\"PI:\", \"Mean:\", np.mean(eva2), \"Var:\", np.var(eva2))\n","print(\"VI:\", \"Mean:\", np.mean(eva3), \"Var:\", np.var(eva3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None: Mean: 157.36 Var: 30279.2304\n","PI: Mean: 3.28 Var: 0.3616\n","VI: Mean: 3.28 Var: 0.3215999999999999\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OpZHMjkShmm2"},"source":["# Rook\n"]},{"cell_type":"code","metadata":{"id":"PoTQjJ5bGDnJ"},"source":["# Radom Walk\n","eva1 = []\n","for i in range(50):\n","  #r.policy_iteration()\n","  p = Piece(piece='rook') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva1.append(len(actions))\n","\n","# Policy Iteration\n","eva2 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='rook') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration()\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva2.append(len(actions))\n","\n","eva3 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='rook') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  r.policy_iteration(k=1)\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva3.append(len(actions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"befO_u21GGPl","executionInfo":{"status":"ok","timestamp":1612313215470,"user_tz":300,"elapsed":212820,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"59c043fc-3b7f-4cde-aeb9-a28a3f0e0801"},"source":["print(\"None:\", \"Mean:\", np.mean(eva1), \"Var:\", np.var(eva1))\n","print(\"PI:\", \"Mean:\", np.mean(eva2), \"Var:\", np.var(eva2))\n","print(\"VI:\", \"Mean:\", np.mean(eva3), \"Var:\", np.var(eva3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None: Mean: 141.82 Var: 17110.627600000003\n","PI: Mean: 3.22 Var: 0.2916\n","VI: Mean: 3.22 Var: 0.21160000000000004\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dreYXe1Ahk83","executionInfo":{"status":"ok","timestamp":1612316079901,"user_tz":300,"elapsed":1139,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"886e7145-b171-456e-d148-5beba9299ab4"},"source":["from scipy import stats\n","stats.ttest_rel(eva2, eva3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ttest_relResult(statistic=0.0, pvalue=1.0)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"QZWEoxOpMRoT"},"source":["eva4 = [] # numnbe of step to get to desired position\n","for i in range(50):\n","  p = Piece(piece='rook') # select a chess agent (knight, bishop or rook)\n","  env = Board() # 8*8 chess board\n","  r = Reinforce(p,env) \n","  for k in range(1000):\n","    eps = 0.5\n","    r.monte_carlo_learning(epsilon=eps)\n","  states, actions, rewards = r.play_episode(state = (0,0), \n","                                            max_steps=1e3, epsilon=0.1)\n","  eva4.append(len(actions))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a_uwAPhMdjH","executionInfo":{"status":"ok","timestamp":1612327431141,"user_tz":300,"elapsed":421,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"2eda58e7-2f27-48cc-a23a-69713b493293"},"source":["print(\"VI:\", \"Mean:\", np.mean(eva4), \"Var:\", np.var(eva4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["VI: Mean: 4.18 Var: 1.9476\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWF3WhFHMwAX","executionInfo":{"status":"ok","timestamp":1612327357095,"user_tz":300,"elapsed":323,"user":{"displayName":"Yuetong Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjled0guJ9UlVUNssv1mWyc5TCUXbCOP3JIGHMPzQ=s64","userId":"07904439503082268536"}},"outputId":"6f90a63e-cd57-47cb-c6b5-f27722c67e26"},"source":["eva4"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3,\n"," 3,\n"," 6,\n"," 17,\n"," 3,\n"," 6,\n"," 63,\n"," 3,\n"," 3,\n"," 4,\n"," 50,\n"," 4,\n"," 3,\n"," 4,\n"," 5,\n"," 4,\n"," 4,\n"," 5,\n"," 3,\n"," 3,\n"," 4,\n"," 23,\n"," 3,\n"," 156,\n"," 96,\n"," 4,\n"," 3,\n"," 5,\n"," 4,\n"," 34,\n"," 42,\n"," 4,\n"," 3,\n"," 4,\n"," 4,\n"," 15,\n"," 5,\n"," 5,\n"," 38,\n"," 4,\n"," 4,\n"," 5,\n"," 3,\n"," 3,\n"," 4,\n"," 3,\n"," 4,\n"," 20,\n"," 60,\n"," 3]"]},"metadata":{"tags":[]},"execution_count":40}]}]}